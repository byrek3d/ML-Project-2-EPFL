{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import models as m\n",
    "import utils as u\n",
    "\n",
    "from surprise.dataset import * \n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import BaselineOnly,CoClustering,SVD,SVDpp,NMF,SlopeOne,KNNBasic\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/data_train.csv', header=0, index_col=0, names=['Id', 'rating'])\n",
    "data = u.preprocess(raw_data).reset_index().drop(columns=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total data \")\n",
    "print(\"-\"*50)\n",
    "print(\"\\nTotal no of ratings :\",data.shape[0])\n",
    "print(\"Total No of Users   :\", len(np.unique(data.user)))\n",
    "print(\"Total No of movies  :\", len(np.unique(data.item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suprise Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader=Reader(rating_scale=(1.0,5.0))\n",
    "formatted_data= Dataset.load_from_df(data[['user','item','rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_factorsSVD=80\n",
    "n_epochsSVD=800\n",
    "lr_allSVD=0.001667\n",
    "reg_allSVD=0.1\n",
    "\n",
    "epochs_SVDpp= 30\n",
    "\n",
    "n_cltr_uCC=13\n",
    "n_cltr_iCC=13\n",
    "n_epochsCC=200\n",
    "\n",
    "bsl_options= {'method': 'als', 'n_epochs': 10, 'reg_u': 15, 'reg_i': 5}\n",
    "\n",
    "model_parameters_user = {\n",
    "      'name': 'pearson',\n",
    "      'user_based': True\n",
    "    }\n",
    "\n",
    "k_user=100\n",
    "\n",
    "model_parameters_movie = {\n",
    "      'name': 'pearson',\n",
    "      'user_based': False\n",
    "    }\n",
    "\n",
    "k_movie=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "print(\"Seperating the data in 2 datasets: one for training the models and one for training the blending model:\")\n",
    "trainset, blending_trainset = train_test_split(formatted_data, test_size=.2 ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as u \n",
    "df_trainset = u.trainset_from_surprise_to_df(trainset)\n",
    "ratings = sparse.csr_matrix((df_trainset.Rating.values, (df_trainset.Movie.values,df_trainset.User.values)))\n",
    "print(\"The training matrix shape is : (movie, user) : \",ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items_per_user, num_users_per_item = u.stat_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = m.split_data(ratings, num_items_per_user, num_users_per_item, p_test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-Training MF SGD\")\n",
    "user_sgd, movie_sgd = m.matrix_factorization_SGD(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMFSGD=[]\n",
    "\n",
    "for uid,iid,_ in blending_trainset: #(row,col) => (user,movie)\n",
    "\n",
    "    user_data = user_sgd[:,uid]  \n",
    "    movie_data = movie_sgd[:,iid]\n",
    "            \n",
    "    prediciton= movie_data @ user_data.T\n",
    "    \n",
    "    dfMFSGD.append(prediciton)\n",
    "dfMFSGD=pd.DataFrame([dfMFSGD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_als,movie_als = m.ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMFALS=[]\n",
    "\n",
    "for uid,iid,_ in blending_trainset: #(row,col) => (user,movie)\n",
    "\n",
    "    user_data = user_als[:,uid]  \n",
    "    movie_data = movie_als[:,iid]\n",
    "            \n",
    "    prediciton= movie_data @ user_data.T\n",
    "    \n",
    "    dfMFALS.append(prediciton)\n",
    "dfMFALS=pd.DataFrame([dfMFALS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-Training global baseline\")\n",
    "baseline_global=m.baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBLGlobal = pd.DataFrame( [baseline_global] *len(blending_trainset) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-Training user baseline\")\n",
    "baseline_user=m.baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBLUser = []\n",
    "for user,movie,_ in blending_trainset:\n",
    "    dfBLUser.append(baseline_user[0,user])\n",
    "dfBLUser = pd.DataFrame(dfBLUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-Training movie baseline\")\n",
    "baseline_movie=m.baseline_movie_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBLMovie = []\n",
    "for user,movie,_ in blending_trainset:\n",
    "    dfBLMovie.append(baseline_movie [movie,0])\n",
    "dfBLMovie = pd.DataFrame(dfBLMovie)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the label of the second dataset in a dataframe\n",
    "label_blending_trainset = []\n",
    "\n",
    "for a,b,c in blending_trainset:\n",
    "    label_blending_trainset.append(c)\n",
    "\n",
    "df_label_blending_trainset=pd.DataFrame(label_blending_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-Training CoCluster\")\n",
    "algoCC= CoClustering(n_cltr_i=n_cltr_iCC, n_cltr_u=n_cltr_uCC, n_epochs=n_epochsCC)\n",
    "algoCC.fit(trainset)\n",
    "\n",
    "print(\"-Training Baseline\")\n",
    "algoBL=BaselineOnly(bsl_options=bsl_options)\n",
    "algoBL.fit(trainset)\n",
    "\n",
    "print(\"-Training SVD\")\n",
    "algoSVD=SVD( n_factors=n_factorsSVD, n_epochs=n_epochsSVD, lr_all=lr_allSVD,reg_all=reg_allSVD)\n",
    "algoSVD.fit(trainset)\n",
    "\n",
    "print(\"-Training SVD++\")\n",
    "algoSVDpp = SVDpp(n_factors=n_factorsSVD, n_epochs=epochs_SVDpp, lr_all=lr_allSVD,reg_all=reg_allSVD)\n",
    "algoSVDpp.fit(trainset)\n",
    "\n",
    "print(\"-Training NMF\")\n",
    "algoNMF = NMF(n_factors=n_factorsNMF, n_epochs=n_epochsNMF, reg_pu=reg_puNMF, reg_qi=reg_qiNMF, reg_bu=reg_buNMF, reg_bi=reg_biNMF)\n",
    "algoNMF.fit(trainset)\n",
    "\n",
    "print(\"-Training KNN on movie\")\n",
    "algoKNNMovie =KNNBasic(model_parameters=model_parameters_movie, k=k_movie)\n",
    "algoKNNMovie.fit(trainset)\n",
    "\n",
    "print(\"-Training KNN on user\")\n",
    "algoKNNUser =KNNBasic(model_parameters=model_parameters_user,k=k_user)\n",
    "algoKNNUser.fit(trainset)\n",
    "\n",
    "print(\"-Training Slope One\")\n",
    "algoSO = SlopeOne()\n",
    "algoSO.fit(trainset)\n",
    "\n",
    "print(\"-For the Blending algorithm, we predict on the second dataset using the trained models\")\n",
    "predCC=algoCC.test(blending_trainset)\n",
    "dfCC=u.pred_from_suprise_to_df(predCC)\n",
    "\n",
    "predBL=algoBL.test(blending_trainset)\n",
    "dfBL=u.pred_from_suprise_to_df(predBL)\n",
    "\n",
    "predSVD=algoSVD.test(blending_trainset)\n",
    "dfSVD=u.pred_from_suprise_to_df(predSVD)\n",
    "\n",
    "predSVDpp=algoSVDpp.test(blending_trainset)\n",
    "dfSVDpp=u.pred_from_suprise_to_df(predSVDpp)\n",
    "\n",
    "predNMF=algoNMF.test(blending_trainset)\n",
    "dfNMF=u.pred_from_suprise_to_df(predNMF)\n",
    "\n",
    "predKNNMovie=algoKNNMovie.test(blending_trainset)\n",
    "dfKNNMovie=u.pred_from_suprise_to_df(predKNNMovie)\n",
    "\n",
    "predKNNUser=algoKNNUser.test(blending_trainset)\n",
    "dfKNNUser=u.pred_from_suprise_to_df(predKNNUser)\n",
    "\n",
    "predSO=algoSO.test(blending_trainset)\n",
    "dfSO=u.pred_from_suprise_to_df(predSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrix Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = sparse.csr_matrix((df_trainset.Rating.values, (df_trainset.User.values,df_trainset.Movie.values)))\n",
    "print(\"The training matrix shape is : (user, movie) : \",sparse_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, movies = sparse_matrix.shape\n",
    "elem = sparse_matrix.count_nonzero()\n",
    "\n",
    "print(\"Sparsity of the training matrix : {0} % \".format((1 - (elem / (users * movies))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating's averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating's average over all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average = sparse_matrix.sum() / sparse_matrix.count_nonzero()\n",
    "print(\"The average rating over all movies of trainset is : {0} \".format(global_average) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating's average per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing the rating's average per user\")\n",
    "\n",
    "user_mean = []   #contains the mean rating for user i at index i\n",
    "\n",
    "for user_index in range(users):\n",
    "    \n",
    "        # find the non-zero ratings for each user in the dataset\n",
    "        ratings = sparse_matrix[user_index, :]\n",
    "        nonzeros_ratings = ratings[ratings.nonzero()]\n",
    "        \n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_ratings.shape[1] != 0:\n",
    "            user_mean.append(nonzeros_ratings.mean())\n",
    "        else:\n",
    "            user_mean.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating's average per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing the rating's average per movie\")\n",
    "\n",
    "movie_mean = []   #contains the mean rating for movie j at index j\n",
    "\n",
    "for movie_index in range(movies):\n",
    "    \n",
    "        # find the non-zero ratings for each user in the dataset\n",
    "        ratings = sparse_matrix[:, movie_index]\n",
    "        nonzeros_ratings = ratings[ratings.nonzero()]\n",
    "        \n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_ratings.shape[1] != 0:\n",
    "            movie_mean.append(nonzeros_ratings.mean())\n",
    "        else:\n",
    "            movie_mean.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of  non zero rows(users) from our sparse matrix\n",
    "row_ind, col_ind = sparse_matrix.nonzero()\n",
    "\n",
    "row_ind = sorted(set(row_ind))   #to have unique values and sorted if needed  \n",
    "col_ind = sorted(set(col_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-User similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 5 \n",
    "print(\"Computing top\",top,\"similar user for each user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_simil_matrix = []\n",
    "\n",
    "for row in row_ind: \n",
    "    # get the similarity row for this user with all other users\n",
    "    simil = cosine_similarity(sparse_matrix.getrow(row), sparse_matrix).ravel()\n",
    "    \n",
    "    # get the index of the top 5 \n",
    "    top_users = np.argsort((simil))[::-1][1:top+1]\n",
    "    user_simil_matrix.append(top_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie-Movie similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 5 \n",
    "print(\"Computing top\",top,\"similar movie for each movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_simil_matrix = []\n",
    "\n",
    "for col in col_ind: \n",
    "    # get the similarity col for this movie with all other movies\n",
    "    simil = cosine_similarity(sparse_matrix.getcol(col).T, sparse_matrix.T).ravel()\n",
    "    # get the index of the top 5 \n",
    "    top_movies = np.argsort((simil))[::-1][1:top+1]\n",
    "    movie_simil_matrix.append(top_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurizing the trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global_Average : Average rating of all the ratings\n",
    " \n",
    "User_Average : User's Average rating\n",
    "\n",
    "Movie_Average : Average rating of this movie\n",
    "\n",
    "Similar users rating of this movie:\n",
    "SimUser1, SimUser2, SimUser3, SimUser4, SimUser5 ( top 5 similar users who rated that movie.. )\n",
    "\n",
    "Similar movies rated by this user:\n",
    "SimMovie1, SimMovie2, SimMovie3, SimMovie4, SimMovie5 ( top 5 similar movies rated by this user.. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind, col_ind = sparse_matrix.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data = pd.DataFrame({'User': row_ind, 'Movie' : col_ind, 'Grade' : sparse_matrix.data, 'Global_Average' : global_average })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['User_Average'] = df_featured_data['User'].map(lambda x: user_mean[x])\n",
    "df_featured_data['Movie_Average'] = df_featured_data['Movie'].map(lambda x: movie_mean[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the indices of the similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimUser1'] = df_featured_data['User'].map(lambda x: int(user_simil_matrix[x][0]))\n",
    "df_featured_data['SimUser2'] = df_featured_data['User'].map(lambda x: int(user_simil_matrix[x][1]))\n",
    "df_featured_data['SimUser3'] = df_featured_data['User'].map(lambda x: int(user_simil_matrix[x][2]))\n",
    "df_featured_data['SimUser4'] = df_featured_data['User'].map(lambda x: int(user_simil_matrix[x][3]))\n",
    "df_featured_data['SimUser5'] = df_featured_data['User'].map(lambda x: int(user_simil_matrix[x][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each similar user need to find the rating that he put for that movie if not available put the average rating of that user as an estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Userfunction1(row):\n",
    "    if(sparse_matrix[row['SimUser1'],row['Movie']] == 0):\n",
    "        return user_mean[int(row['SimUser1'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['SimUser1'],row['Movie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimUser1'] = df_featured_data.apply(Userfunction1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Userfunction2(row):\n",
    "    if(sparse_matrix[row['SimUser2'],row['Movie']] == 0):\n",
    "        return user_mean[int(row['SimUser2'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['SimUser2'],row['Movie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimUser2'] = df_featured_data.apply(Userfunction2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Userfunction3(row):\n",
    "    if(sparse_matrix[row['SimUser3'],row['Movie']] == 0):\n",
    "        return user_mean[int(row['SimUser3'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['SimUser3'],row['Movie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimUser3'] = df_featured_data.apply(Userfunction3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Userfunction4(row):\n",
    "    if(sparse_matrix[row['SimUser4'],row['Movie']] == 0):\n",
    "        return user_mean[int(row['SimUser4'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['SimUser4'],row['Movie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimUser4'] = df_featured_data.apply(Userfunction4,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Userfunction5(row):\n",
    "    if(sparse_matrix[row['SimUser5'],row['Movie']] == 0):\n",
    "        return user_mean[int(row['SimUser5'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['SimUser5'],row['Movie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimUser5'] = df_featured_data.apply(Userfunction5,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the indices of the similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimMovie1'] = df_featured_data['Movie'].map(lambda x: int(movie_simil_matrix[x][0]))\n",
    "df_featured_data['SimMovie2'] = df_featured_data['Movie'].map(lambda x: int(movie_simil_matrix[x][1]))\n",
    "df_featured_data['SimMovie3'] = df_featured_data['Movie'].map(lambda x: int(movie_simil_matrix[x][2]))\n",
    "df_featured_data['SimMovie4'] = df_featured_data['Movie'].map(lambda x: int(movie_simil_matrix[x][3]))\n",
    "df_featured_data['SimMovie5'] = df_featured_data['Movie'].map(lambda x: int(movie_simil_matrix[x][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each similar movie we need to find the rating that the user has given to it if not available give the similar movie average rating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Moviefunction1(row):\n",
    "    if(sparse_matrix[row['User'],row['SimMovie1']] == 0):\n",
    "        return movie_mean[int(row['SimMovie1'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['User'],row['SimMovie1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimMovie1'] = df_featured_data.apply(Moviefunction1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Moviefunction2(row):\n",
    "    if(sparse_matrix[row['User'],row['SimMovie2']] == 0):\n",
    "        return movie_mean[int(row['SimMovie2'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['User'],row['SimMovie2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimMovie2'] = df_featured_data.apply(Moviefunction2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Moviefunction3(row):\n",
    "    if(sparse_matrix[row['User'],row['SimMovie3']] == 0):\n",
    "        return movie_mean[int(row['SimMovie3'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['User'],row['SimMovie3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimMovie3'] = df_featured_data.apply(Moviefunction3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Moviefunction4(row):\n",
    "    if(sparse_matrix[row['User'],row['SimMovie4']] == 0):\n",
    "        return movie_mean[int(row['SimMovie4'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['User'],row['SimMovie4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimMovie4'] = df_featured_data.apply(Moviefunction4,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Moviefunction5(row):\n",
    "    if(sparse_matrix[row['User'],row['SimMovie5']] == 0):\n",
    "        return movie_mean[int(row['SimMovie5'])]\n",
    "    else:\n",
    "        return sparse_matrix[row['User'],row['SimMovie5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_data['SimMovie5'] = df_featured_data.apply(Moviefunction5,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurizing the blending trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blending_trainset=[]\n",
    "\n",
    "for u,m,r in blending_trainset:\n",
    "    df_blending_trainset.append([u,m,r])\n",
    "    \n",
    "df_featured_blending_trainset = pd.DataFrame(df_blending_trainset)\n",
    "df_featured_blending_trainset = df_featured_blending_trainset.rename({0:'User',1:'Movie',2:'Rating'},axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_blending_trainset['User_Average'] = df_featured_blending_trainset['User'].map(lambda x: user_mean[x])\n",
    "df_featured_blending_trainset['Movie_Average'] = df_featured_blending_trainset['Movie'].map(lambda x: movie_mean[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the indices of the similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_blending_trainset['SimUser1'] = df_featured_blending_trainset['User'].map(lambda x: int(user_simil_matrix[x][0]))\n",
    "df_featured_blending_trainset['SimUser2'] = df_featured_blending_trainset['User'].map(lambda x: int(user_simil_matrix[x][1]))\n",
    "df_featured_blending_trainset['SimUser3'] = df_featured_blending_trainset['User'].map(lambda x: int(user_simil_matrix[x][2]))\n",
    "df_featured_blending_trainset['SimUser4'] = df_featured_blending_trainset['User'].map(lambda x: int(user_simil_matrix[x][3]))\n",
    "df_featured_blending_trainset['SimUser5'] = df_featured_blending_trainset['User'].map(lambda x: int(user_simil_matrix[x][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each similar user need to find the rating that he put for that movie if not available put the average rating of that user as an estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_blending_trainset['SimUser1'] = df_featured_blending_trainset.apply(Userfunction1,axis=1)\n",
    "df_featured_blending_trainset['SimUser2'] = df_featured_blending_trainset.apply(Userfunction2,axis=1)\n",
    "df_featured_blending_trainset['SimUser3'] = df_featured_blending_trainset.apply(Userfunction3,axis=1)\n",
    "df_featured_blending_trainset['SimUser4'] = df_featured_blending_trainset.apply(Userfunction4,axis=1)\n",
    "df_featured_blending_trainset['SimUser5'] = df_featured_blending_trainset.apply(Userfunction5,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_blending_trainset['SimMovie1'] = df_featured_blending_trainset['Movie'].map(lambda x: int(movie_simil_matrix[x][0]))\n",
    "df_featured_blending_trainset['SimMovie2'] = df_featured_blending_trainset['Movie'].map(lambda x: int(movie_simil_matrix[x][1]))\n",
    "df_featured_blending_trainset['SimMovie3'] = df_featured_blending_trainset['Movie'].map(lambda x: int(movie_simil_matrix[x][2]))\n",
    "df_featured_blending_trainset['SimMovie4'] = df_featured_blending_trainset['Movie'].map(lambda x: int(movie_simil_matrix[x][3]))\n",
    "df_featured_blending_trainset['SimMovie5'] = df_featured_blending_trainset['Movie'].map(lambda x: int(movie_simil_matrix[x][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each similar movie we need to find the rating that the user has given to it if not available give the similar movie average rating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_blending_trainset['SimMovie1'] = df_featured_blending_trainset.apply(Moviefunction1,axis=1)\n",
    "df_featured_blending_trainset['SimMovie2'] = df_featured_blending_trainset.apply(Moviefunction2,axis=1)\n",
    "df_featured_blending_trainset['SimMovie3'] = df_featured_blending_trainset.apply(Moviefunction3,axis=1)\n",
    "df_featured_blending_trainset['SimMovie4'] = df_featured_blending_trainset.apply(Moviefunction4,axis=1)\n",
    "df_featured_blending_trainset['SimMovie5'] = df_featured_blending_trainset.apply(Moviefunction5,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_blending_trainset.SimUser1=df_featured_blending_trainset.SimUser1.astype(float)\n",
    "df_featured_blending_trainset.SimUser2=df_featured_blending_trainset.SimUser2.astype(float)\n",
    "df_featured_blending_trainset.SimUser3=df_featured_blending_trainset.SimUser3.astype(float)\n",
    "df_featured_blending_trainset.SimUser4=df_featured_blending_trainset.SimUser4.astype(float)\n",
    "df_featured_blending_trainset.SimUser5=df_featured_blending_trainset.SimUser5.astype(float)\n",
    "df_featured_blending_trainset.SimMovie1=df_featured_blending_trainset.SimMovie1.astype(float)\n",
    "df_featured_blending_trainset.SimMovie2=df_featured_blending_trainset.SimMovie2.astype(float)\n",
    "df_featured_blending_trainset.SimMovie3=df_featured_blending_trainset.SimMovie3.astype(float)\n",
    "df_featured_blending_trainset.SimMovie4=df_featured_blending_trainset.SimMovie4.astype(float)\n",
    "df_featured_blending_trainset.SimMovie5=df_featured_blending_trainset.SimMovie5.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured_blending_trainset.drop(['Rating'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Must save a copy with the \"User\" and \"Movie\" columns to be used in predict_on_models\n",
    "df_featured_blending_trainset_no_user_movie=df_featured_blending_trainset.drop(['User','Movie'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboosting case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_val=pd.concat([dfCC,dfBL,dfSVD,dfSVDpp,dfNMF,dfKNNMovie,dfKNNUser,dfSO,dfMFSGD,dfMFALS,dfBLGlobal,dfBLMovie, dfBLUser],ignore_index=True,axis=1)\n",
    "df_val=df_val.rename({0:'dfCC',1:'dfBL',2:'dfSVD',3:'dfSVDpp',4:'dfNMF',5:'dfKNNMovie',6:'dfKNNUser',7:'dfSO',8:'dfMFSGD',9:'dfMFALS',10:'dfBLGlobal',11:'dfBLMovie',12:'dfBLUser'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val=pd.concat([df_val,df_featured_blending_trainset_no_user_movie],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb= xgb.XGBRegressor(silent=True, n_jobs=25, random_state=1,n_estimators=100)\n",
    "\n",
    "model_xgb.fit(df_val,label_blending_trainset, eval_metric='rmse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, preds = u.predict_on_all_models_and_features_xgb(model_xgb,[algoCC, algoBL,algoSVD, algoSVDpp,algoNMF,algoKNNMovie,algoKNNUser,algoSO],\n",
    "                                          [user_sgd, movie_sgd],[user_als, movie_als],\n",
    "                                          baseline_global,baseline_movie,baseline_user,df_featured_blending_trainset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "u.create_csv_submission(ids, preds, \"submissionBlendedXgbFull.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
