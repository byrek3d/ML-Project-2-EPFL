{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 1682, number of users: 943\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"movielens100k.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 20, min # of users per item = 1.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "#     valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "#     valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings=ratings # don't drop anything\n",
    "#     valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, user].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of original ratings. (# of row, # of col): (1682, 943)\n",
      "the shape of valid ratings. (# of row, # of col): (1152, 943)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch in assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-505fb4a8626f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m valid_ratings, train, test = split_data(\n\u001b[0;32m----> 4\u001b[0;31m     ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_train_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-36bf094f973e>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(ratings, num_items_per_user, num_users_per_item, min_num_ratings, p_test)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# add to train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# add to test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_intXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;31m# Everything else takes the normal path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mIndexMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_mul_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m             if not ((broadcast_row or x.shape[0] == i.shape[0]) and\n\u001b[1;32m     97\u001b[0m                     (broadcast_col or x.shape[1] == i.shape[1])):\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape mismatch in assignment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch in assignment"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of baseline using the global mean: [[ 1.12489888]].\n"
     ]
    }
   ],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    # find the non zero ratings in the train\n",
    "    nonzero_train = train[train.nonzero()]\n",
    "\n",
    "    # calculate the global mean\n",
    "    global_mean_train = nonzero_train.mean()\n",
    "\n",
    "    # find the non zero ratings in the test\n",
    "    nonzero_test = test[test.nonzero()].todense()\n",
    "\n",
    "    # predict the ratings as global mean\n",
    "    mse = calculate_mse(nonzero_test, global_mean_train)\n",
    "    rmse = np.sqrt(1.0 * mse / nonzero_test.shape[1])\n",
    "    print(\"test RMSE of baseline using the global mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the user mean: [[ 1.05356297]].\n"
     ]
    }
   ],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "\n",
    "    for user_index in range(num_users):\n",
    "        # find the non-zero ratings for each user in the training dataset\n",
    "        train_ratings = train[:, user_index]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "        \n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            user_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each user in the test dataset\n",
    "        test_ratings = test[:, user_index]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, user_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the user mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the item mean: [[ 1.01449251]].\n"
     ]
    }
   ],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    for item_index in range(num_items):\n",
    "        # find the non-zero ratings for each item in the training dataset\n",
    "        train_ratings = train[item_index, :]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "\n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            item_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each movie in the test dataset\n",
    "        test_ratings = test[item_index, :]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, item_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the item mean: {v}.\".format(v=rmse))\n",
    "    \n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "        \n",
    "    num_item, num_user = train.get_shape()\n",
    "\n",
    "    user_features = np.random.rand(num_features, num_user)\n",
    "    item_features = np.random.rand(num_features, num_item)\n",
    "\n",
    "    # start by item features.\n",
    "    item_nnz = train.getnnz(axis=1)\n",
    "    item_sum = train.sum(axis=1)\n",
    "\n",
    "    for ind in range(num_item):\n",
    "        item_features[0, ind] = item_sum[ind, 0] / item_nnz[ind]\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    mse = 0\n",
    "    for row, col in nz:\n",
    "        item_info = item_features[:, row]\n",
    "        user_info = user_features[:, col]\n",
    "        mse += (data[row, col] - user_info.T.dot(item_info)) ** 2\n",
    "    return np.sqrt(1.0 * mse / len(nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.081497632563063.\n",
      "iter: 1, RMSE on training set: 1.029803849784576.\n",
      "iter: 2, RMSE on training set: 1.0019809035101255.\n",
      "iter: 3, RMSE on training set: 0.9853666299258862.\n",
      "iter: 4, RMSE on training set: 0.9750716860449808.\n",
      "iter: 5, RMSE on training set: 0.9704009306183263.\n",
      "iter: 6, RMSE on training set: 0.9669991741568986.\n",
      "iter: 7, RMSE on training set: 0.9630762628484878.\n",
      "iter: 8, RMSE on training set: 0.9615511910698763.\n",
      "iter: 9, RMSE on training set: 0.9589299480929678.\n",
      "iter: 10, RMSE on training set: 0.959732333780623.\n",
      "iter: 11, RMSE on training set: 0.9582914490852443.\n",
      "iter: 12, RMSE on training set: 0.9577931080789052.\n",
      "iter: 13, RMSE on training set: 0.9575839427031514.\n",
      "iter: 14, RMSE on training set: 0.9571950816510866.\n",
      "iter: 15, RMSE on training set: 0.9562654534229875.\n",
      "iter: 16, RMSE on training set: 0.9559287414630159.\n",
      "iter: 17, RMSE on training set: 0.9561185200623608.\n",
      "iter: 18, RMSE on training set: 0.9559476507020113.\n",
      "iter: 19, RMSE on training set: 0.9557771739754993.\n",
      "RMSE on test data: 0.9983315283064381.\n"
     ]
    }
   ],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "            # update W_d (item_features[:, d]) and Z_n (user_features[:, n])\n",
    "            item_info = item_features[:, d]\n",
    "            user_info = user_features[:, n]\n",
    "            err = train[d, n] - user_info.T.dot(item_info)\n",
    "    \n",
    "            # calculate the gradient and update\n",
    "            item_features[:, d] += gamma * (err * user_info - lambda_item * item_info)\n",
    "            user_features[:, n] += gamma * (err * item_info - lambda_user * user_info)\n",
    "\n",
    "        rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "\n",
    "    # evaluate the test error\n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "\n",
    "matrix_factorization_SGD(train, test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_user[user] * lambda_user\"\"\"\n",
    "    num_user = nnz_items_per_user.shape[0]\n",
    "    num_feature = item_features.shape[0]\n",
    "    lambda_I = lambda_user * sp.eye(num_feature)\n",
    "    updated_user_features = np.zeros((num_feature, num_user))\n",
    "\n",
    "    for user, items in nz_user_itemindices:\n",
    "        # extract the columns corresponding to the prediction for given item\n",
    "        M = item_features[:, items]\n",
    "        \n",
    "        # update column row of user features\n",
    "        V = M @ train[items, user]\n",
    "        A = M @ M.T + nnz_items_per_user[user] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_user_features[:, user] = np.copy(X.T)\n",
    "    return updated_user_features\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_item[item] * lambda_item\"\"\"\n",
    "    num_item = nnz_users_per_item.shape[0]\n",
    "    num_feature = user_features.shape[0]\n",
    "    lambda_I = lambda_item * sp.eye(num_feature)\n",
    "    updated_item_features = np.zeros((num_feature, num_item))\n",
    "\n",
    "    for item, users in nz_item_userindices:\n",
    "        # extract the columns corresponding to the prediction for given user\n",
    "        M = user_features[:, users]\n",
    "        V = M @ train[item, users].T\n",
    "        A = M @ M.T + nnz_users_per_item[item] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_item_features[:, item] = np.copy(X.T)\n",
    "    return updated_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start the ALS algorithm...\n",
      "RMSE on training set: 1.9127836193917878.\n",
      "RMSE on training set: 1.161584665057034.\n",
      "RMSE on training set: 1.0415094612421196.\n",
      "RMSE on training set: 0.9930375983713047.\n",
      "RMSE on training set: 0.9690284075235571.\n",
      "RMSE on training set: 0.9556714892005632.\n",
      "RMSE on training set: 0.9476261066311378.\n",
      "RMSE on training set: 0.9425014892677404.\n",
      "RMSE on training set: 0.9391068535761989.\n",
      "RMSE on training set: 0.9367959149557584.\n",
      "RMSE on training set: 0.9351925819501763.\n",
      "RMSE on training set: 0.9340654686318525.\n",
      "RMSE on training set: 0.933265907448913.\n",
      "RMSE on training set: 0.932695173827355.\n",
      "RMSE on training set: 0.9322860749095511.\n",
      "RMSE on training set: 0.9319920437189873.\n",
      "RMSE on training set: 0.9317803800771869.\n",
      "RMSE on training set: 0.931627901871879.\n",
      "RMSE on training set: 0.9315180619189877.\n",
      "RMSE on training set: 0.93143899116918.\n",
      "test RMSE after running ALS: 0.9704191683650746.\n"
     ]
    }
   ],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # get the number of non-zero ratings for each user and item\n",
    "    nnz_items_per_user, nnz_users_per_item = train.getnnz(axis=0), train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "    # run ALS\n",
    "    print(\"\\nstart the ALS algorithm...\")\n",
    "    while change > stop_criterion:\n",
    "        # update user feature & item feature\n",
    "        user_features = update_user_feature(\n",
    "            train, item_features, lambda_user,\n",
    "            nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(\n",
    "            train, user_features, lambda_item,\n",
    "            nnz_users_per_item, nz_item_userindices)\n",
    "\n",
    "        error = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(error))\n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "\n",
    "    # evaluate the test error\n",
    "    nnz_row, nnz_col = test.nonzero()\n",
    "    nnz_test = list(zip(nnz_row, nnz_col))\n",
    "    rmse = compute_error(test, user_features, item_features, nnz_test)\n",
    "    print(\"test RMSE after running ALS: {v}.\".format(v=rmse))\n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
