{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the pipeline using only libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import models as m\n",
    "import pandas as pd\n",
    "from surprise.dataset import * \n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/data_train.csv', header=0, index_col=0, names=['Id', 'rating'])\n",
    "\n",
    "dataFrame = preprocess(raw_data).reset_index().drop(columns=['Id'])\n",
    "reader=Reader(rating_scale=(1.0,5.0))\n",
    "\n",
    "\n",
    "formatted_data= Dataset.load_from_df(dataFrame[['user','item','rating']],reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9931  0.9889  0.9913  0.9924  0.9911  0.9913  0.0014  \n",
      "MAE (testset)     0.7985  0.7954  0.7966  0.7983  0.7982  0.7974  0.0012  \n",
      "Fit time          2.36    2.76    2.84    2.78    2.74    2.69    0.17    \n",
      "Test time         1.61    2.06    1.60    1.80    1.61    1.74    0.18    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.99312093, 0.98885278, 0.99126683, 0.99237913, 0.99109735]),\n",
       " 'test_mae': array([0.79852387, 0.79544176, 0.79663821, 0.79829122, 0.79817104]),\n",
       " 'fit_time': (2.356489896774292,\n",
       "  2.7612810134887695,\n",
       "  2.835474967956543,\n",
       "  2.778623104095459,\n",
       "  2.7424051761627197),\n",
       " 'test_time': (1.612243890762329,\n",
       "  2.0636308193206787,\n",
       "  1.6035840511322021,\n",
       "  1.8023018836975098,\n",
       "  1.6082658767700195)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import BaselineOnly\n",
    "\n",
    "\n",
    "algo = BaselineOnly()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=5, measures=['RMSE', 'MAE'])\n",
    "\n",
    "# param_grid = {}\n",
    "# gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176952\n"
     ]
    }
   ],
   "source": [
    "ids, preds = predict_on_model(algo)\n",
    "create_csv_submission(ids, preds, \"submissionBase.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.0276  1.0263  1.0288  1.0276  0.0010  \n",
      "MAE (testset)     0.8224  0.8209  0.8230  0.8221  0.0009  \n",
      "Fit time          598.91  600.64  592.82  597.46  3.35    \n",
      "Test time         4.36    2.85    5.91    4.37    1.25    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.02763212, 1.02627285, 1.02878825]),\n",
       " 'test_mae': array([0.82243375, 0.82088088, 0.82304007]),\n",
       " 'fit_time': (598.9082748889923, 600.6407120227814, 592.8245830535889),\n",
       " 'test_time': (4.355956792831421, 2.8517940044403076, 5.905275106430054)}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "\n",
    "algo =SVD(n_factors=1000, n_epochs=20, lr_all=0.005,reg_all=0.02)\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=3, measures=['RMSE', 'MAE'])# FOUND RMSE: 1.0276 locally\n",
    "\n",
    "\n",
    "# param_grid = {'n_factors':[100,120],'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "#               'reg_all': [0.4, 0.6]}\n",
    "# gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "\n",
    "# # best RMSE score\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176952\n"
     ]
    }
   ],
   "source": [
    "ids, preds = predict_on_model(algo)\n",
    "create_csv_submission(ids, preds, \"submissionSVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN on Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.0607  1.0594  1.0609  1.0603  0.0006  \n",
      "MAE (testset)     0.8741  0.8717  0.8732  0.8730  0.0010  \n",
      "Fit time          5.84    6.52    6.18    6.18    0.28    \n",
      "Test time         60.17   54.85   53.60   56.21   2.85    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.06065018, 1.05943611, 1.06087716]),\n",
       " 'test_mae': array([0.87406779, 0.8717202 , 0.8731543 ]),\n",
       " 'fit_time': (5.837891101837158, 6.5175018310546875, 6.176137924194336),\n",
       " 'test_time': (60.17310905456543, 54.85204076766968, 53.60230302810669)}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "\n",
    "algo =m.movie_knn()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=3, measures=['RMSE', 'MAE']) # FOUND RMSE: 1.0603 locally, 1.133 online\n",
    "\n",
    "# param_grid = {'n_neighbors':[3,5,9],'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "#               'reg_all': [0.4, 0.6]}\n",
    "# gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "\n",
    "# # best RMSE score\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176952\n"
     ]
    }
   ],
   "source": [
    "ids, preds = predict_on_model(algo)\n",
    "create_csv_submission(ids, preds, \"submissionKNNMovie.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN on User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.0437  1.0414  1.0408  1.0420  0.0012  \n",
      "MAE (testset)     0.8395  0.8375  0.8375  0.8382  0.0009  \n",
      "Fit time          204.42  216.13  305.80  242.12  45.29   \n",
      "Test time         511.53  516.26  638.12  555.30  58.59   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.04369672, 1.04137051, 1.04082306]),\n",
       " 'test_mae': array([0.83947996, 0.83752981, 0.83752798]),\n",
       " 'fit_time': (204.41919207572937, 216.13488912582397, 305.80421924591064),\n",
       " 'test_time': (511.52813696861267, 516.2617599964142, 638.116250038147)}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "\n",
    "algo =m.user_knn()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=3, measures=['RMSE', 'MAE'])# RMSE: 1.0420 locally, 1.140 online\n",
    "\n",
    "# param_grid = {'n_neighbors':[3,5,9],'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "#               'reg_all': [0.4, 0.6]}\n",
    "# gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "\n",
    "# # best RMSE score\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176952\n"
     ]
    }
   ],
   "source": [
    "ids, preds = predict_on_model(algo)\n",
    "create_csv_submission(ids, preds, \"submissionKNNUser.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SlopeOne\n",
    "\n",
    "algo = SlopeOnepeOnepeOne()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=5, measures=['RMSE', 'MAE'])\n",
    "\n",
    "# param_grid = {}\n",
    "# gs = GridSearchCV(SlopeOne, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, preds = predict_on_model(algo)\n",
    "create_csv_submission(ids, preds, \"submissionSlopeOne.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
