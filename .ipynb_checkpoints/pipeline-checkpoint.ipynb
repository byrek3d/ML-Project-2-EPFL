{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the pipeline using only libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import models as m\n",
    "import utils as u\n",
    "import pandas as pd\n",
    "from surprise.dataset import * \n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/data_train.csv', header=0, index_col=0, names=['Id', 'rating'])\n",
    "\n",
    "dataFrame = u.preprocess(raw_data).reset_index().drop(columns=['Id'])\n",
    "reader=Reader(rating_scale=(1.0,5.0))\n",
    "\n",
    "\n",
    "formatted_data= Dataset.load_from_df(dataFrame[['user','item','rating']],reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly\n",
    "\n",
    "\n",
    "algo = BaselineOnly()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=5, measures=['RMSE', 'MAE'])\n",
    "\n",
    "# param_grid = {}\n",
    "# gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, preds = u.predict_on_model(algo)\n",
    "u.create_csv_submission(ids, preds, \"submissionBase.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "\n",
    "algo =SVD(n_factors=1000, n_epochs=20, lr_all=0.005,reg_all=0.02)\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=3, measures=['RMSE', 'MAE'])# FOUND RMSE: 1.0276 locally\n",
    "\n",
    "\n",
    "# param_grid = {'n_factors':[100,120],'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "#               'reg_all': [0.4, 0.6]}\n",
    "# gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "\n",
    "# # best RMSE score\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, preds = u.predict_on_model(algo)\n",
    "u.create_csv_submission(ids, preds, \"submissionSVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN on Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "\n",
    "algo =m.movie_knn()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=3, measures=['RMSE', 'MAE']) # FOUND RMSE: 1.0603 locally, 1.133 online\n",
    "\n",
    "# param_grid = {'n_neighbors':[3,5,9],'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "#               'reg_all': [0.4, 0.6]}\n",
    "# gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "\n",
    "# # best RMSE score\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, preds = u.predict_on_model(algo)\n",
    "u.create_csv_submission(ids, preds, \"submissionKNNMovie.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN on User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "\n",
    "algo =m.user_knn()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=3, measures=['RMSE', 'MAE'])# RMSE: 1.0420 locally, 1.140 online\n",
    "\n",
    "# param_grid = {'n_neighbors':[3,5,9],'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "#               'reg_all': [0.4, 0.6]}\n",
    "# gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "\n",
    "# # best RMSE score\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, preds = u.predict_on_model(algo)\n",
    "u.create_csv_submission(ids, preds, \"submissionKNNUser.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SlopeOne\n",
    "\n",
    "algo = SlopeOne()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=5, measures=['RMSE', 'MAE'])# RMSE: 0.9923 locally, 1.143 online\n",
    "\n",
    "# param_grid = {}\n",
    "# gs = GridSearchCV(SlopeOne, param_grid, measures=['rmse', 'mae'], cv=3,joblib_verbose=1, n_jobs=-1)\n",
    "# gs.fit(formatted_data)\n",
    "# print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, preds = u.predict_on_model(algo)\n",
    "u.create_csv_submission(ids, preds, \"submissionSlopeOne.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm CoClustering on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0047  1.0040  1.0018  1.0041  1.0042  1.0038  0.0010  \n",
      "MAE (testset)     0.8068  0.8071  0.8056  0.8067  0.8061  0.8065  0.0005  \n",
      "Fit time          18.62   20.27   20.23   20.19   37.24   23.31   6.99    \n",
      "Test time         2.09    2.19    1.83    4.71    3.64    2.89    1.11    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.00471382, 1.00403069, 1.00179728, 1.00409181, 1.00423735]),\n",
       " 'test_mae': array([0.80680981, 0.80712163, 0.80560541, 0.80666197, 0.80610796]),\n",
       " 'fit_time': (18.623739004135132,\n",
       "  20.274076223373413,\n",
       "  20.233531713485718,\n",
       "  20.189019918441772,\n",
       "  37.243990659713745),\n",
       " 'test_time': (2.0878589153289795,\n",
       "  2.1923019886016846,\n",
       "  1.833517074584961,\n",
       "  4.712648868560791,\n",
       "  3.6423721313476562)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = m.co_clustering()\n",
    "cross_validate(algo, formatted_data, verbose=True,cv=5, measures=['RMSE', 'MAE'])# RMSE: 1.0038 locally, 1.140 online\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, preds = u.predict_on_model(algo)\n",
    "u.create_csv_submission(ids, preds, \"submissionCoClustering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
