{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 8, min # of users per item = 3.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]   #return only when it's true\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]   \n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  #Why not directly [valid_items,valid_users] ?  \n",
    "    \n",
    "    # ***************************************************\n",
    "    # split the data and return train and test data. \n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    index = valid_ratings.nonzero()  #tuple of array \n",
    "\n",
    "    order_shuffled = np.arange(0,len(index[0]))\n",
    "    np.random.shuffle(order_shuffled)\n",
    "     \n",
    "    index_shuffled = (index[0][order_shuffled],index[1][order_shuffled])\n",
    "\n",
    "    test_index_size = int(p_test*len(order_shuffled))\n",
    "    \n",
    "    index_test = (index_shuffled[0][:test_index_size],index_shuffled[1][:test_index_size])\n",
    "  \n",
    "    index_train = (index_shuffled[0][test_index_size:],index_shuffled[1][test_index_size:])\n",
    "\n",
    "    test[index_test] =  valid_ratings[index_test]\n",
    "    \n",
    "    train[index_train] = valid_ratings[index_train]\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in valid data:{v}\".format(v=valid_ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in valid data:1176873\n",
      "Total number of nonzero elements in train data:1059186\n",
      "Total number of nonzero elements in test data:117687\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "#plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1171646234717394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    \n",
    "    global_mean_train = train[train.nonzero()].mean()\n",
    "    \n",
    "    test_nonzero_dense = test[test.nonzero()].todense()\n",
    "    \n",
    "    mse = calculate_mse( test_nonzero_dense, global_mean_train )\n",
    "    \n",
    "    rmse = np.sqrt( mse / test_nonzero_dense.shape[1] )\n",
    "    \n",
    "    return rmse[0,0]\n",
    "    \n",
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0292372231810407"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    count = 0 \n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    sums=train.sum(axis=0) #sum for each user\n",
    "    \n",
    "    mean_user=np.zeros((1,num_users))\n",
    "\n",
    "    for j in range(0,num_users):\n",
    "        if(sums[0,j] != 0):\n",
    "            elems = train[:,j]\n",
    "            elems_nonzero = elems[elems.nonzero()]\n",
    "            mean_user[0,j] = elems_nonzero.mean()\n",
    "    \n",
    "        for i in range(test.shape[0]):\n",
    "            if(test[i,j] != 0):\n",
    "                mean_user_elem = mean_user[0,j]\n",
    "                mse += (test[i,j]-mean_user_elem )**2\n",
    "                count+= 1\n",
    "   \n",
    "    rmse = np.sqrt( mse / count )\n",
    "    \n",
    "    return rmse\n",
    "baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0919855243000396"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    count = 0 \n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    sums=train.sum(axis=1) #sum for each user\n",
    "    \n",
    "    mean_item=np.zeros((num_items,1))\n",
    "\n",
    "    for i in range(0,num_items):\n",
    "        if(sums[i,0] != 0):\n",
    "            elems = train[i,:]\n",
    "            elems_nonzero = elems[elems.nonzero()]\n",
    "            mean_item[i,0] = elems_nonzero.mean()\n",
    "    \n",
    "        for j in range(test.shape[1]):\n",
    "            if(test[i,j] != 0):\n",
    "                mean_item_elem = mean_item[i,0]\n",
    "                mse += (test[i,j]-mean_item_elem)**2\n",
    "                count+= 1\n",
    "   \n",
    "    rmse = np.sqrt( mse / count )\n",
    "    \n",
    "    return rmse\n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **item mean prediction** gives us the best approximation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "    \n",
    "    num_item, num_user = train.get_shape()\n",
    "    \n",
    "    user_features = np.random.rand(num_features,num_user)  #(K,N)\n",
    "    item_features = np.random.rand(num_features,num_item)  #(K,D)\n",
    "    \n",
    "    #do we need to do anything else ? \n",
    "        \n",
    "    return user_features,item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    mse=0\n",
    "    for row,col in nz:\n",
    "        w_d = item_features[:,row]\n",
    "        z_n = user_features[:,col]\n",
    "        prediction= w_d @ z_n.T\n",
    "        error_prediction = (data[row,col] - prediction ) **2 \n",
    "        mse+=error_prediction\n",
    "    \n",
    "    return np.sqrt(mse / len(nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.0396454698328181.\n",
      "iter: 1, RMSE on training set: 1.0349595382492598.\n",
      "iter: 2, RMSE on training set: 1.0349705134397549.\n",
      "iter: 3, RMSE on training set: 1.0329840001506103.\n",
      "iter: 4, RMSE on training set: 1.0314520506262004.\n",
      "iter: 5, RMSE on training set: 1.0300808532240444.\n",
      "iter: 6, RMSE on training set: 1.0285397866898172.\n",
      "iter: 7, RMSE on training set: 1.0273312057023696.\n",
      "iter: 8, RMSE on training set: 1.0266935358979976.\n",
      "iter: 9, RMSE on training set: 1.026072190435157.\n",
      "iter: 10, RMSE on training set: 1.026056677957059.\n",
      "iter: 11, RMSE on training set: 1.0256322871361312.\n",
      "iter: 12, RMSE on training set: 1.0255265448223012.\n",
      "iter: 13, RMSE on training set: 1.0253143200675616.\n",
      "iter: 14, RMSE on training set: 1.0251330057401447.\n",
      "iter: 15, RMSE on training set: 1.0252774077749784.\n",
      "iter: 16, RMSE on training set: 1.025199164616075.\n",
      "iter: 17, RMSE on training set: 1.0251349855343557.\n",
      "iter: 18, RMSE on training set: 1.0252174562988263.\n",
      "iter: 19, RMSE on training set: 1.025096519021199.\n",
      "RMSE on test data: 1.0328153623669527.\n"
     ]
    }
   ],
   "source": [
    "def matrix_factorization_SGD(train, test,reg=True):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)   #Z0.T,W0\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "            \n",
    "            item_data = item_features[:,d]  \n",
    "            user_data = user_features[:,n]\n",
    "            \n",
    "            prediciton_error = train[d, n] - item_data @ user_data.T\n",
    "        \n",
    "            #compute derivative wrt w\n",
    "            grad_w = -prediciton_error * user_data  \n",
    "                \n",
    "            #compute derivative wrt z \n",
    "            grad_z = -prediciton_error * item_data\n",
    "   \n",
    "            #update \n",
    "            if(reg):\n",
    "            \n",
    "                item_features[:,d]-= gamma * ( grad_w + lambda_item * item_data)\n",
    "                user_features[:,n]-= gamma * ( grad_z + lambda_user * user_data)\n",
    "            \n",
    "            else:\n",
    "                item_features[:,d]-= gamma * grad_w\n",
    "                user_features[:,n]-= gamma * grad_z\n",
    "        \n",
    "        rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "\n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    \n",
    "    return item_features, user_features\n",
    "\n",
    "item_features, user_features = matrix_factorization_SGD(train, test)    #Regularized\n",
    "\n",
    "\n",
    "##matrix_factorization_SGD(train, test, False) #Not regularized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9990, 20)\n",
      "(20, 999)\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "print(item_features.T.shape)\n",
    "print(user_features.shape)\n",
    "\n",
    "X = item_features.T @ user_features\n",
    "\n",
    "with open('submission.csv' , 'w') as writeFile: \n",
    "    writer = csv.writer(writeFile)\n",
    "    \n",
    "    for j in range(X.shape[1]):\n",
    "        for i in range(X.shape[0]):\n",
    "            if(X[i,j] != 0):\n",
    "                s= \"r{0}_c{1}\".format(i+1,j+1)\n",
    "                row= [s, str(X[i,j])]\n",
    "                writer.writerows(row)\n",
    "\n",
    "writeFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_user[user] * lambda_user\"\"\"\n",
    "    \n",
    "    \n",
    "    num_user = nnz_items_per_user.shape[0]\n",
    "    num_feature = item_features.shape[0]\n",
    "    lambda_I = lambda_user * np.eye(num_feature)\n",
    "    updated_user_features = np.zeros((num_feature, num_user))\n",
    "\n",
    "    for user, items in nz_user_itemindices:\n",
    "        # extract the columns corresponding to the prediction for given item\n",
    "        M = item_features[:, items]\n",
    "        \n",
    "        # update column row of user features\n",
    "        V = M @ train[items, user]\n",
    "        A = M @ M.T + nnz_items_per_user[user] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_user_features[:, user] = np.copy(X.T)\n",
    "    return updated_user_features\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_item[item] * lambda_item\"\"\"\n",
    "    num_item = nnz_users_per_item.shape[0]\n",
    "    num_feature = user_features.shape[0]\n",
    "    lambda_I = lambda_item * sp.eye(num_feature)\n",
    "    updated_item_features = np.zeros((num_feature, num_item))\n",
    "\n",
    "    for item, users in nz_item_userindices:\n",
    "        # extract the columns corresponding to the prediction for given user\n",
    "        M = user_features[:, users]\n",
    "        V = M @ train[item, users].T\n",
    "        A = M @ M.T + nnz_users_per_item[item] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_item_features[:, item] = np.copy(X.T)\n",
    "    return updated_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start the ALS algorithm...\n",
      "RMSE on training set: 1.2268608177178733.\n",
      "RMSE on training set: 1.0679719056734243.\n",
      "RMSE on training set: 1.011176082495169.\n",
      "RMSE on training set: 0.9809366938195246.\n",
      "RMSE on training set: 0.9626783232194683.\n",
      "RMSE on training set: 0.9515927754786456.\n",
      "RMSE on training set: 0.9448637043216529.\n",
      "RMSE on training set: 0.940663999584706.\n",
      "RMSE on training set: 0.937942581733915.\n",
      "RMSE on training set: 0.9361197282526463.\n",
      "RMSE on training set: 0.9348679291407508.\n",
      "RMSE on training set: 0.9339931005581322.\n",
      "RMSE on training set: 0.9333744071964116.\n",
      "RMSE on training set: 0.9329333817287765.\n",
      "RMSE on training set: 0.9326173771071264.\n",
      "RMSE on training set: 0.932390212919941.\n",
      "RMSE on training set: 0.9322265982307127.\n",
      "RMSE on training set: 0.9321086434183049.\n",
      "RMSE on training set: 0.9320235906035975.\n",
      "test RMSE after running ALS: 0.9610301226500155.\n"
     ]
    }
   ],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # get the number of non-zero ratings for each user and item\n",
    "    nnz_items_per_user, nnz_users_per_item = train.getnnz(axis=0), train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "    # run ALS\n",
    "    print(\"\\nstart the ALS algorithm...\")\n",
    "    while change > stop_criterion:\n",
    "        # update user feature & item feature\n",
    "        user_features = update_user_feature(\n",
    "            train, item_features, lambda_user,\n",
    "            nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(\n",
    "            train, user_features, lambda_item,\n",
    "            nnz_users_per_item, nz_item_userindices)\n",
    "\n",
    "        error = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(error))\n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "\n",
    "    # evaluate the test error\n",
    "    nnz_row, nnz_col = test.nonzero()\n",
    "    nnz_test = list(zip(nnz_row, nnz_col))\n",
    "    rmse = compute_error(test, user_features, item_features, nnz_test)\n",
    "    print(\"test RMSE after running ALS: {v}.\".format(v=rmse))\n",
    "\n",
    "ALS(train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
